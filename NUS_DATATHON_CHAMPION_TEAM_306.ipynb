{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Myrica7/My-website/blob/main/NUS_DATATHON_CHAMPION_TEAM_306.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvb3YhINneuq"
      },
      "source": [
        "##### The cell below is for you to keep track of the libraries used and install those libraries quickly\n",
        "##### Ensure that the proper library names are used and the syntax of `%pip install PACKAGE_NAME` is followed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nT0h9KfMneur",
        "outputId": "7817debf-7f72-46cc-f83a-58468b84e93c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas\n",
        "%pip install matplotlib\n",
        "# add commented pip installation lines for packages used as shown above for ease of testing\n",
        "# the line should be of the format %pip install PACKAGE_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwPlSoYsneus"
      },
      "source": [
        "## **DO NOT CHANGE** the filepath variable\n",
        "##### Instead, create a folder named 'data' in your current working directory and\n",
        "##### have the .csv file inside that. A relative path *must* be used when loading data into pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "e_Y3YvACneus",
        "outputId": "12493bb6-5512-4d89-92de-a33806821af7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/catA_train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-db2b4309a5bb>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# the initialised filepath MUST be a relative path to a folder named data that contains the parquet file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/catA_train.csv'"
          ]
        }
      ],
      "source": [
        "# Can have as many cells as you want for code\n",
        "import pandas as pd\n",
        "filepath = \"/catA_train.csv\"\n",
        "#remember to change back the filepath\n",
        "\n",
        "# the initialised filepath MUST be a relative path to a folder named data that contains the parquet file\n",
        "\n",
        "df = pd.read_csv(filepath)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLdAQVXsneut"
      },
      "source": [
        "### **ALL** Code for machine learning and dataset analysis should be entered below.\n",
        "##### Ensure that your code is clear and readable.\n",
        "##### Comments and Markdown notes are advised to direct attention to pieces of code you deem useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03X-_Onhneut"
      },
      "outputs": [],
      "source": [
        "#Import packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "#to ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kht6LTLmneut"
      },
      "outputs": [],
      "source": [
        "print(df.shape)\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BO22T6iSneut"
      },
      "outputs": [],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRsktnhOneut"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "c7EuRdoeo_Aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aHMScAzneuu"
      },
      "source": [
        "1. Data cleaning -- Handle missing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxZkR13Vneuu"
      },
      "outputs": [],
      "source": [
        "#Remove Square Footage column\n",
        "df2 = df.drop(['Square Footage', 'Fiscal Year End'], axis=1)\n",
        "#Drop rows with NA value for LATITUDE and LONGITUDE columns\n",
        "df2 = df2.dropna(subset=['LATITUDE','LONGITUDE'])\n",
        "#Include entries from active companies only\n",
        "df2 = df2[df2['Company Status (Active/Inactive)'] == 'Active']\n",
        "\n",
        "print(df2.shape)\n",
        "df2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lteLe8cTneuu"
      },
      "source": [
        "One-Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBOH14A9neuu"
      },
      "outputs": [],
      "source": [
        "df3 = pd.get_dummies(df2, columns = ['Entity Type'])\n",
        "df3.loc[df3['Entity Type_Branch'] == True, 'Entity Type_Branch'] = 1\n",
        "df3.loc[df3['Entity Type_Branch'] == False, 'Entity Type_Branch'] = 0\n",
        "df3.loc[df3['Entity Type_Independent'] == True, 'Entity Type_Independent'] = 1\n",
        "df3.loc[df3['Entity Type_Independent'] == False, 'Entity Type_Independent'] = 0\n",
        "df3.loc[df3['Entity Type_Parent'] == True, 'Entity Type_Parent'] = 1\n",
        "df3.loc[df3['Entity Type_Parent'] == False, 'Entity Type_Parent'] = 0\n",
        "df3.loc[df3['Entity Type_Subsidiary'] == True, 'Entity Type_Subsidiary'] = 1\n",
        "df3.loc[df3['Entity Type_Subsidiary'] == False, 'Entity Type_Subsidiary'] = 0\n",
        "df3.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv7CCYPMneuu"
      },
      "source": [
        "2. EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5COKI5Cneuv"
      },
      "source": [
        "Make plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wjlle6pZneuv"
      },
      "outputs": [],
      "source": [
        "#Check correlation\n",
        "numerical_col = df3[['LATITUDE','LONGITUDE','SIC Code','8-Digit SIC Code','Year Found','Is Domestic Ultimate','Is Global Ultimate','Entity Type_Branch','Entity Type_Independent','Entity Type_Parent','Entity Type_Subsidiary','Employees (Domestic Ultimate Total)', 'Employees (Global Ultimate Total)', 'Sales (Domestic Ultimate Total USD)', 'Sales (Global Ultimate Total USD)']]\n",
        "numerical_col.corr()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a histogram\n",
        "sns.histplot(numerical_col['Year Found'], bins = 30, color='blue')\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('Count of Companies Based on Year Founded')\n",
        "plt.xlabel('Year Found')\n",
        "plt.ylabel('Number of companies')\n",
        "\n",
        "# Show the plot\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8VKTdwjorgb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create pairplot\n",
        "sns.pairplot(numerical_col)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xz4PG2rwtTjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sns.heatmap(numerical_col.corr(), annot=True, vmin=-1, vmax=1, annot_kws={\"size\": 5})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0qUzMp640fzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGYEYn1-neuv"
      },
      "source": [
        "Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P73AlEFjneuv"
      },
      "outputs": [],
      "source": [
        "#Feature Ranking (check correlation between features and target variable)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD33ibtFneuv"
      },
      "source": [
        "EDA - Data manipulation\n",
        "\n",
        "Data type conversion and possibly make new features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yaa-xGPEneuv"
      },
      "outputs": [],
      "source": [
        "#Convert \"Is Domestic Ultimate\" and \"Is Global Ultimate\" to boolean\n",
        "df2['Is Domestic Ultimate'] = df2['Is Domestic Ultimate'] == 1\n",
        "df2['Is Global Ultimate'] = df2['Is Global Ultimate'] == 1\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWbBG08Dneuv"
      },
      "source": [
        "3. Model Training and Model Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Selection"
      ],
      "metadata": {
        "id": "znkaE4DBIEWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "EFdk7edzIHej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target variable\n",
        "X = df2.drop('Sales (Domestic Ultimate Total USD)', axis=1)\n",
        "y = df2['Sales (Domestic Ultimate Total USD)']\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=306)\n",
        "\n",
        "# Initialize the GradientBoostingRegressor\n",
        "model = xgb.XGBRegressor(objective=\"reg:linear\", random_state=3-6)"
      ],
      "metadata": {
        "id": "hGGm-hIyIf9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross Validation"
      ],
      "metadata": {
        "id": "bWkjNYVsJaHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lists to store results\n",
        "n_folds_values = list(range(4, 16))\n",
        "mean_r2_scores = []\n",
        "std_r2_scores = []\n",
        "\n",
        "# Iterate over different numbers of folds\n",
        "for n_folds in n_folds_values:\n",
        "    # Use k-fold cross-validation with the current number of folds\n",
        "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    # Perform cross-validation and get R-squared scores\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='r2')\n",
        "\n",
        "    # Append mean and standard deviation of R-squared scores to lists\n",
        "    mean_r2_scores.append(cv_scores.mean())\n",
        "    std_r2_scores.append(cv_scores.std())\n",
        "\n",
        "# Plot the results\n",
        "plt.errorbar(n_folds_values, mean_r2_scores, yerr=std_r2_scores, marker='o', linestyle='-', label='R-squared scores')\n",
        "plt.xlabel('Number of Folds')\n",
        "plt.ylabel('R-squared Score')\n",
        "plt.title('Cross-Validated R-squared Scores for Different Numbers of Folds')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lMzHarneJVZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4J7Ii6MOneuv"
      },
      "source": [
        "4. Model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbZv7YxJneuv"
      },
      "source": [
        "Performance Metrics -- Loss Functions (Adjusted R^2, MAE, MSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bz6-qRKneuv"
      },
      "source": [
        "## The cell below is **NOT** to be removed\n",
        "##### The function is to be amended so that it accepts the given input (dataframe) and returns the required output (list).\n",
        "##### It is recommended to test the function out prior to submission\n",
        "-------------------------------------------------------------------------------------------------------------------------------\n",
        "##### The hidden_data parsed into the function below will have the same layout columns wise as the dataset *SENT* to you\n",
        "##### Thus, ensure that steps taken to modify the initial dataset to fit into the model are also carried out in the function below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIUucaU4neuv"
      },
      "outputs": [],
      "source": [
        "def testing_hidden_data(hidden_data: pd.DataFrame) -> list:\n",
        "    '''DO NOT REMOVE THIS FUNCTION.\n",
        "\n",
        "The function accepts a dataframe as input and return an iterable (list)\n",
        "of binary classes as output.\n",
        "\n",
        "The function should be coded to test on hidden data\n",
        "and should include any preprocessing functions needed for your model to perform.\n",
        "\n",
        "All relevant code MUST be included in this function.'''\n",
        "\n",
        "    result = []\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xIA3xWcneuv"
      },
      "source": [
        "##### Cell to check testing_hidden_data function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5NEK0Owneuv"
      },
      "outputs": [],
      "source": [
        "# This cell should output a list of predictions.\n",
        "test_df = pd.read_csv(filepath)\n",
        "test_df = test_df.drop(columns=['Sales (Domestic Ultimate Total USD)'])\n",
        "print(testing_hidden_data(test_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKZeVyWuneuv"
      },
      "source": [
        "### Please have the filename renamed and ensure that it can be run with the requirements above being met. All the best!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}